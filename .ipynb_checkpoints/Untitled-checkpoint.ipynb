{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TrainDocs_1/resume_1201_d1.txt\n",
      "Saved TrainDocs_1/resume_604_d1.txt\n",
      "Saved TrainDocs_1/resume_106_d1.txt\n",
      "Saved TrainDocs_1/resume_2462_d1.txt\n",
      "Saved TrainDocs_1/resume_2372_d1.txt\n",
      "Saved TrainDocs_1/resume_340_d1.txt\n",
      "Saved TrainDocs_1/resume_1003_d1.txt\n",
      "Saved TrainDocs_1/resume_2357_d1.txt\n",
      "Saved TrainDocs_1/resume_2038_d1.txt\n",
      "Saved TrainDocs_1/resume_377_d1.txt\n",
      "Saved TrainDocs_1/resume_1076_d1.txt\n",
      "Saved TrainDocs_1/resume_951_d1.txt\n",
      "Saved TrainDocs_1/resume_2017_d1.txt\n",
      "Saved TrainDocs_1/resume_1386_d1.txt\n",
      "Saved TrainDocs_1/resume_2318_d1.txt\n",
      "Saved TrainDocs_1/resume_92_d1.txt\n",
      "Saved TrainDocs_1/resume_1087_d1.txt\n",
      "Saved TrainDocs_1/resume_1953_d1.txt\n",
      "Saved TrainDocs_1/resume_2127_d1.txt\n",
      "Saved TrainDocs_1/resume_1705_d1.txt\n",
      "Saved TrainDocs_1/resume_1888_d1.txt\n",
      "Saved TrainDocs_1/resume_2191_d1.txt\n",
      "Saved TrainDocs_1/resume_1632_d1.txt\n",
      "Saved TrainDocs_1/resume_46_d1.txt\n",
      "Saved TrainDocs_1/resume_2138_d1.txt\n",
      "Saved TrainDocs_1/resume_2435_d1.txt\n",
      "Saved TrainDocs_1/resume_1189_d1.txt\n",
      "Saved TrainDocs_1/resume_955_d1.txt\n",
      "Saved TrainDocs_1/resume_871_d1.txt\n",
      "Saved TrainDocs_1/resume_4_d1.txt\n",
      "Saved TrainDocs_1/resume_885_d1.txt\n",
      "Saved TrainDocs_1/resume_650_d1.txt\n",
      "Saved TrainDocs_1/resume_2297_d1.txt\n",
      "Saved TrainDocs_1/resume_1477_d1.txt\n",
      "Saved TrainDocs_1/resume_45_d1.txt\n",
      "Saved TrainDocs_1/resume_1818_d1.txt\n",
      "Saved TrainDocs_1/resume_1636_d1.txt\n",
      "Saved TrainDocs_1/resume_2121_d1.txt\n",
      "Saved TrainDocs_1/resume_2440_d1.txt\n",
      "Saved TrainDocs_1/resume_698_d1.txt\n",
      "Saved TrainDocs_1/resume_1177_d1.txt\n",
      "Saved TrainDocs_1/resume_706_d1.txt\n",
      "Saved TrainDocs_1/resume_251_d1.txt\n",
      "Saved TrainDocs_1/resume_2483_d1.txt\n",
      "Saved TrainDocs_1/resume_1245_d1.txt\n",
      "Saved TrainDocs_1/resume_510_d1.txt\n",
      "Saved TrainDocs_1/resume_1366_d1.txt\n",
      "Saved TrainDocs_1/resume_2161_d1.txt\n",
      "Saved TrainDocs_1/resume_1967_d1.txt\n",
      "Saved TrainDocs_1/resume_2315_d1.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"Resume.csv\")\n",
    "\n",
    "# Select 4 random rows\n",
    "random_rows = df.sample(n=50)\n",
    "\n",
    "# Create a folder named TrainDocs_1 if it doesn't exist\n",
    "folder_name = \"TrainDocs_1\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Iterate over the selected rows and save each 'Resume_txt' to a unique text file\n",
    "for index, row in random_rows.iterrows():\n",
    "    resume_text = row['Resume_str']\n",
    "    filename = os.path.join(folder_name, f\"resume_{index}_d1.txt\")\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(resume_text)\n",
    "    print(f\"Saved {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Resume_str', 'Resume_html', 'Category'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"final_merged_dataset2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Developer Python Developer Philadelphia...</td>\n",
       "      <td>Python_Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Developer Python Developer Python Devel...</td>\n",
       "      <td>Python_Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R&amp;D Engineer R&amp;D Engineer R&amp;D Engineer - Nokia...</td>\n",
       "      <td>Python_Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr. Full Stack Developer Sr. Full Stack Develo...</td>\n",
       "      <td>Python_Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Full Stack Python Developer Sr. Full Stack...</td>\n",
       "      <td>Python_Developer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Resume          Category\n",
       "0  Python Developer Python Developer Philadelphia...  Python_Developer\n",
       "1  Python Developer Python Developer Python Devel...  Python_Developer\n",
       "2  R&D Engineer R&D Engineer R&D Engineer - Nokia...  Python_Developer\n",
       "3  Sr. Full Stack Developer Sr. Full Stack Develo...  Python_Developer\n",
       "4  Sr. Full Stack Python Developer Sr. Full Stack...  Python_Developer"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TrainDocs_1/resume_3587_d2.txt\n",
      "Saved TrainDocs_1/resume_8076_d2.txt\n",
      "Saved TrainDocs_1/resume_4689_d2.txt\n",
      "Saved TrainDocs_1/resume_5210_d2.txt\n",
      "Saved TrainDocs_1/resume_7712_d2.txt\n",
      "Saved TrainDocs_1/resume_7381_d2.txt\n",
      "Saved TrainDocs_1/resume_4794_d2.txt\n",
      "Saved TrainDocs_1/resume_4663_d2.txt\n",
      "Saved TrainDocs_1/resume_1997_d2.txt\n",
      "Saved TrainDocs_1/resume_6120_d2.txt\n",
      "Saved TrainDocs_1/resume_7228_d2.txt\n",
      "Saved TrainDocs_1/resume_2867_d2.txt\n",
      "Saved TrainDocs_1/resume_1943_d2.txt\n",
      "Saved TrainDocs_1/resume_1767_d2.txt\n",
      "Saved TrainDocs_1/resume_725_d2.txt\n",
      "Saved TrainDocs_1/resume_2999_d2.txt\n",
      "Saved TrainDocs_1/resume_8205_d2.txt\n",
      "Saved TrainDocs_1/resume_5076_d2.txt\n",
      "Saved TrainDocs_1/resume_6056_d2.txt\n",
      "Saved TrainDocs_1/resume_2966_d2.txt\n",
      "Saved TrainDocs_1/resume_4962_d2.txt\n",
      "Saved TrainDocs_1/resume_7649_d2.txt\n",
      "Saved TrainDocs_1/resume_4544_d2.txt\n",
      "Saved TrainDocs_1/resume_1117_d2.txt\n",
      "Saved TrainDocs_1/resume_7611_d2.txt\n",
      "Saved TrainDocs_1/resume_2802_d2.txt\n",
      "Saved TrainDocs_1/resume_3977_d2.txt\n",
      "Saved TrainDocs_1/resume_1558_d2.txt\n",
      "Saved TrainDocs_1/resume_6508_d2.txt\n",
      "Saved TrainDocs_1/resume_6192_d2.txt\n",
      "Saved TrainDocs_1/resume_5853_d2.txt\n",
      "Saved TrainDocs_1/resume_667_d2.txt\n",
      "Saved TrainDocs_1/resume_752_d2.txt\n",
      "Saved TrainDocs_1/resume_2697_d2.txt\n",
      "Saved TrainDocs_1/resume_2842_d2.txt\n",
      "Saved TrainDocs_1/resume_4482_d2.txt\n",
      "Saved TrainDocs_1/resume_4525_d2.txt\n",
      "Saved TrainDocs_1/resume_216_d2.txt\n",
      "Saved TrainDocs_1/resume_2238_d2.txt\n",
      "Saved TrainDocs_1/resume_7761_d2.txt\n",
      "Saved TrainDocs_1/resume_7484_d2.txt\n",
      "Saved TrainDocs_1/resume_2411_d2.txt\n",
      "Saved TrainDocs_1/resume_6176_d2.txt\n",
      "Saved TrainDocs_1/resume_6942_d2.txt\n",
      "Saved TrainDocs_1/resume_7566_d2.txt\n",
      "Saved TrainDocs_1/resume_3695_d2.txt\n",
      "Saved TrainDocs_1/resume_7813_d2.txt\n",
      "Saved TrainDocs_1/resume_5083_d2.txt\n",
      "Saved TrainDocs_1/resume_3198_d2.txt\n",
      "Saved TrainDocs_1/resume_3497_d2.txt\n"
     ]
    }
   ],
   "source": [
    "# Select 4 random rows\n",
    "random_rows = df2.sample(n=50)\n",
    "\n",
    "# Create a folder named TrainDocs_1 if it doesn't exist\n",
    "folder_name = \"TrainDocs_1\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Iterate over the selected rows and save each 'Resume_txt' to a unique text file\n",
    "for index, row in random_rows.iterrows():\n",
    "    resume_text = row['Resume']\n",
    "    filename = os.path.join(folder_name, f\"resume_{index}_d2.txt\")\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(resume_text)\n",
    "    print(f\"Saved {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resume_1003_d1.txt', 'resume_1009_d1.txt', 'resume_1054_d1.txt', 'resume_1062_d1.txt', 'resume_106_d1.txt', 'resume_1076_d1.txt', 'resume_1087_d1.txt', 'resume_1177_d1.txt', 'resume_1180_d1.txt', 'resume_1189_d1.txt', 'resume_1201_d1.txt', 'resume_120_d1.txt', 'resume_1222_d1.txt', 'resume_1245_d1.txt', 'resume_1366_d1.txt', 'resume_1386_d1.txt', 'resume_1464_d1.txt', 'resume_1477_d1.txt', 'resume_1632_d1.txt', 'resume_1636_d1.txt', 'resume_1640_d1.txt', 'resume_1705_d1.txt', 'resume_1775_d1.txt', 'resume_1791_d1.txt', 'resume_1818_d1.txt', 'resume_1829_d1.txt', 'resume_1884_d1.txt', 'resume_1888_d1.txt', 'resume_188_d1.txt', 'resume_1953_d1.txt', 'resume_1967_d1.txt', 'resume_1974_d1.txt', 'resume_1995_d1.txt', 'resume_2017_d1.txt', 'resume_2038_d1.txt', 'resume_2065_d1.txt', 'resume_2084_d1.txt', 'resume_2088_d1.txt', 'resume_2113_d1.txt', 'resume_2121_d1.txt', 'resume_2127_d1.txt', 'resume_2138_d1.txt', 'resume_2146_d1.txt', 'resume_2161_d1.txt', 'resume_2191_d1.txt', 'resume_2248_d1.txt', 'resume_2256_d1.txt', 'resume_2294_d1.txt', 'resume_2297_d1.txt', 'resume_2315_d1.txt', 'resume_2318_d1.txt', 'resume_2347_d1.txt', 'resume_2353_d1.txt', 'resume_2357_d1.txt', 'resume_2372_d1.txt', 'resume_2419_d1.txt', 'resume_2426_d1.txt', 'resume_2435_d1.txt', 'resume_2440_d1.txt', 'resume_244_d1.txt', 'resume_2462_d1.txt', 'resume_2483_d1.txt', 'resume_251_d1.txt', 'resume_291_d1.txt', 'resume_310_d1.txt', 'resume_340_d1.txt', 'resume_342_d1.txt', 'resume_343_d1.txt', 'resume_377_d1.txt', 'resume_45_d1.txt', 'resume_46_d1.txt', 'resume_4_d1.txt', 'resume_501_d1.txt', 'resume_510_d1.txt', 'resume_531_d1.txt', 'resume_53_d1.txt', 'resume_544_d1.txt', 'resume_557_d1.txt', 'resume_604_d1.txt', 'resume_650_d1.txt', 'resume_691_d1.txt', 'resume_698_d1.txt', 'resume_699_d1.txt', 'resume_706_d1.txt', 'resume_716_d1.txt', 'resume_736_d1.txt', 'resume_791_d1.txt', 'resume_792_d1.txt', 'resume_819_d1.txt', 'resume_83_d1.txt', 'resume_845_d1.txt', 'resume_864_d1.txt', 'resume_871_d1.txt', 'resume_885_d1.txt', 'resume_887_d1.txt', 'resume_92_d1.txt', 'resume_951_d1.txt', 'resume_955_d1.txt', 'resume_994_d1.txt']\n",
      "IDs in d1 files: ['1003', '1009', '1054', '1062', '106', '1076', '1087', '1177', '1180', '1189', '1201', '120', '1222', '1245', '1366', '1386', '1464', '1477', '1632', '1636', '1640', '1705', '1775', '1791', '1818', '1829', '1884', '1888', '188', '1953', '1967', '1974', '1995', '2017', '2038', '2065', '2084', '2088', '2113', '2121', '2127', '2138', '2146', '2161', '2191', '2248', '2256', '2294', '2297', '2315', '2318', '2347', '2353', '2357', '2372', '2419', '2426', '2435', '2440', '244', '2462', '2483', '251', '291', '310', '340', '342', '343', '377', '45', '46', '4', '501', '510', '531', '53', '544', '557', '604', '650', '691', '698', '699', '706', '716', '736', '791', '792', '819', '83', '845', '864', '871', '885', '887', '92', '951', '955', '994']\n",
      "IDs in d2 files: ['1117', '1128', '1390', '1539', '1558', '164', '1767', '1943', '1947', '1997', '2050', '216', '2198', '2238', '2411', '2573', '2692', '2697', '2802', '2842', '2867', '2966', '2999', '3050', '3144', '3198', '3317', '3497', '3587', '3609', '3695', '3802', '3948', '3977', '4021', '4250', '4285', '432', '4482', '4525', '4544', '4663', '4689', '4731', '4769', '4787', '4794', '4871', '4892', '4962', '5018', '5076', '5083', '50', '513', '5185', '5210', '5514', '5719', '5727', '5839', '5853', '6056', '6066', '6120', '6176', '6192', '6207', '6211', '6214', '6268', '627', '6300', '6304', '6508', '667', '6692', '6878', '6942', '6954', '7076', '7097', '7133', '7228', '725', '7381', '7435', '7459', '7484', '752', '7566', '7611', '7649', '7712', '7761', '7813', '7861', '8076', '8205', '8231']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def extract_id_from_filename(filename):\n",
    "    # Extract ID number from the filename\n",
    "    return filename.split(\"_\")[1]\n",
    "\n",
    "def categorize_ids(folder_path):\n",
    "    d1_ids = []\n",
    "    d2_ids = []\n",
    "    d1_file_names = []\n",
    "    \n",
    "    # Check if the provided path is a directory\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"{folder_path} is not a valid directory.\")\n",
    "        return d1_ids, d2_ids\n",
    "    \n",
    "    # Get a list of all files in the directory\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Categorize IDs based on file names\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\"_d1.txt\"):\n",
    "            d1_file_names.append(file_name)\n",
    "            d1_ids.append(extract_id_from_filename(file_name))\n",
    "        elif file_name.endswith(\"_d2.txt\"):\n",
    "            d2_ids.append(extract_id_from_filename(file_name))\n",
    "    print(d1_file_names)\n",
    "    \n",
    "    return d1_ids, d2_ids\n",
    "\n",
    "# Example usage\n",
    "folder_path = \"./TrainDocs_1\"\n",
    "d1_ids, d2_ids = categorize_ids(folder_path)\n",
    "\n",
    "print(\"IDs in d1 files:\", d1_ids)\n",
    "print(\"IDs in d2 files:\", d2_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printed: 0\n",
      "Printed: 100\n",
      "Printed: 200\n",
      "Printed: 300\n",
      "Printed: 400\n",
      "Printed: 500\n",
      "Printed: 600\n",
      "Printed: 700\n",
      "Printed: 800\n",
      "Printed: 900\n",
      "Printed: 1000\n",
      "Printed: 1100\n",
      "Printed: 1200\n",
      "Printed: 1300\n",
      "Printed: 1400\n",
      "Printed: 1500\n",
      "Printed: 1600\n",
      "Printed: 1700\n",
      "Printed: 1800\n",
      "Printed: 1900\n",
      "Printed: 2000\n",
      "Printed: 2100\n",
      "Printed: 2200\n",
      "Printed: 2300\n",
      "Printed: 2400\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"Resume.csv\")\n",
    "\n",
    "\n",
    "# Create a folder named TrainDocs_1 if it doesn't exist\n",
    "folder_name = \"TestDocs\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Iterate over the selected rows and save each 'Resume_txt' to a unique text file\n",
    "for index, row in df.iterrows():\n",
    "    if str(index) not in d1_ids:\n",
    "        resume_text = row['Resume_str']\n",
    "        filename = os.path.join(folder_name, f\"resume_{index}_d1.txt\")\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(resume_text)\n",
    "        if (index % 100 == 0):\n",
    "            print(\"Printed: \" + str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"final_merged_dataset2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printed: 0\n",
      "Printed: 100\n",
      "Printed: 200\n",
      "Printed: 300\n",
      "Printed: 400\n",
      "Printed: 500\n",
      "Printed: 600\n",
      "Printed: 700\n",
      "Printed: 800\n",
      "Printed: 900\n",
      "Printed: 1000\n",
      "Printed: 1100\n",
      "Printed: 1200\n",
      "Printed: 1300\n",
      "Printed: 1400\n",
      "Printed: 1500\n",
      "Printed: 1600\n",
      "Printed: 1700\n",
      "Printed: 1800\n",
      "Printed: 1900\n",
      "Printed: 2000\n",
      "Printed: 2100\n",
      "Printed: 2200\n",
      "Printed: 2300\n",
      "Printed: 2400\n",
      "Printed: 2500\n",
      "Printed: 2600\n",
      "Printed: 2700\n",
      "Printed: 2800\n",
      "Printed: 2900\n",
      "Printed: 3000\n",
      "Printed: 3100\n",
      "Printed: 3200\n",
      "Printed: 3300\n",
      "Printed: 3400\n",
      "Printed: 3500\n",
      "Printed: 3600\n",
      "Printed: 3700\n",
      "Printed: 3800\n",
      "Printed: 3900\n",
      "Printed: 4000\n",
      "Printed: 4100\n",
      "Printed: 4200\n",
      "Printed: 4300\n",
      "Printed: 4400\n",
      "Printed: 4500\n",
      "Printed: 4600\n",
      "Printed: 4700\n",
      "Printed: 4800\n",
      "Printed: 4900\n",
      "Printed: 5000\n",
      "Printed: 5100\n",
      "Printed: 5200\n",
      "Printed: 5300\n",
      "Printed: 5400\n",
      "Printed: 5500\n",
      "Printed: 5600\n",
      "Printed: 5700\n",
      "Printed: 5800\n",
      "Printed: 5900\n",
      "Printed: 6000\n",
      "Printed: 6100\n",
      "Printed: 6200\n",
      "Printed: 6400\n",
      "Printed: 6500\n",
      "Printed: 6600\n",
      "Printed: 6700\n",
      "Printed: 6800\n",
      "Printed: 6900\n",
      "Printed: 7000\n",
      "Printed: 7100\n",
      "Printed: 7200\n",
      "Printed: 7300\n",
      "Printed: 7400\n",
      "Printed: 7500\n",
      "Printed: 7600\n",
      "Printed: 7700\n",
      "Printed: 7800\n",
      "Printed: 7900\n",
      "Printed: 8000\n",
      "Printed: 8100\n",
      "Printed: 8200\n"
     ]
    }
   ],
   "source": [
    "# Create a folder named TrainDocs_1 if it doesn't exist\n",
    "folder_name = \"TestDocs\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Iterate over the selected rows and save each 'Resume_txt' to a unique text file\n",
    "for index, row in df2.iterrows():\n",
    "    if str(index) not in d2_ids:\n",
    "        resume_text = row['Resume']\n",
    "        filename = os.path.join(folder_name, f\"resume_{index}_d2.txt\")\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(resume_text)\n",
    "        if (index % 100 == 0):\n",
    "            print(\"Printed: \" + str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
